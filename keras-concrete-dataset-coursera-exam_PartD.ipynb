{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":7721085,"sourceType":"datasetVersion","datasetId":4510133}],"dockerImageVersionId":30746,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Concrete composition analysis using deep learning with Keras\n\n## Aim: \nThis project aims to apply a linear regression using a neural network with Keras to analyse data on the composition of concrete\n","metadata":{}},{"cell_type":"code","source":"## import the libraries\nfrom numpy import loadtxt\nimport numpy as np\nimport pandas as pd\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error as MSE\nfrom math import sqrt\nimport time","metadata":{"execution":{"iopub.status.busy":"2024-07-30T11:51:18.135249Z","iopub.execute_input":"2024-07-30T11:51:18.135592Z","iopub.status.idle":"2024-07-30T11:51:30.631468Z","shell.execute_reply.started":"2024-07-30T11:51:18.135565Z","shell.execute_reply":"2024-07-30T11:51:30.630432Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"2024-07-30 11:51:20.159286: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-07-30 11:51:20.159384: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-07-30 11:51:20.285560: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"code","source":"# load the dataset\n# dataset = loadtxt('/kaggle/input/concrete-data/concrete_data.csv', delimiter=',',skiprows=1)\ndataset = pd.read_csv('/kaggle/input/concrete-data/concrete_data.csv')\ndataset.head()","metadata":{"execution":{"iopub.status.busy":"2024-07-30T11:51:30.633399Z","iopub.execute_input":"2024-07-30T11:51:30.634299Z","iopub.status.idle":"2024-07-30T11:51:30.679705Z","shell.execute_reply.started":"2024-07-30T11:51:30.634263Z","shell.execute_reply":"2024-07-30T11:51:30.678753Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"   Cement  Blast Furnace Slag  Fly Ash  Water  Superplasticizer  \\\n0   540.0                 0.0      0.0  162.0               2.5   \n1   540.0                 0.0      0.0  162.0               2.5   \n2   332.5               142.5      0.0  228.0               0.0   \n3   332.5               142.5      0.0  228.0               0.0   \n4   198.6               132.4      0.0  192.0               0.0   \n\n   Coarse Aggregate  Fine Aggregate  Age  Strength  \n0            1040.0           676.0   28     79.99  \n1            1055.0           676.0   28     61.89  \n2             932.0           594.0  270     40.27  \n3             932.0           594.0  365     41.05  \n4             978.4           825.5  360     44.30  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Cement</th>\n      <th>Blast Furnace Slag</th>\n      <th>Fly Ash</th>\n      <th>Water</th>\n      <th>Superplasticizer</th>\n      <th>Coarse Aggregate</th>\n      <th>Fine Aggregate</th>\n      <th>Age</th>\n      <th>Strength</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>540.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>162.0</td>\n      <td>2.5</td>\n      <td>1040.0</td>\n      <td>676.0</td>\n      <td>28</td>\n      <td>79.99</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>540.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>162.0</td>\n      <td>2.5</td>\n      <td>1055.0</td>\n      <td>676.0</td>\n      <td>28</td>\n      <td>61.89</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>332.5</td>\n      <td>142.5</td>\n      <td>0.0</td>\n      <td>228.0</td>\n      <td>0.0</td>\n      <td>932.0</td>\n      <td>594.0</td>\n      <td>270</td>\n      <td>40.27</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>332.5</td>\n      <td>142.5</td>\n      <td>0.0</td>\n      <td>228.0</td>\n      <td>0.0</td>\n      <td>932.0</td>\n      <td>594.0</td>\n      <td>365</td>\n      <td>41.05</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>198.6</td>\n      <td>132.4</td>\n      <td>0.0</td>\n      <td>192.0</td>\n      <td>0.0</td>\n      <td>978.4</td>\n      <td>825.5</td>\n      <td>360</td>\n      <td>44.30</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"# Data preparation\nWe need to specify the target for the training, ie the strength of the concrete. \nThe variables that affect the strenght are the remaining columns.","metadata":{}},{"cell_type":"code","source":"# split the data into target and predictors \ndataset_columns = dataset.columns\n# all columns except Strength\npredictors = dataset[dataset_columns[dataset_columns != 'Strength']] \ntarget = dataset['Strength'] # Strength column","metadata":{"execution":{"iopub.status.busy":"2024-07-30T11:51:35.094741Z","iopub.execute_input":"2024-07-30T11:51:35.095467Z","iopub.status.idle":"2024-07-30T11:51:35.105953Z","shell.execute_reply.started":"2024-07-30T11:51:35.095425Z","shell.execute_reply":"2024-07-30T11:51:35.104854Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"# Part A: Build a baseline model\nNeural network structure: 1 hidden layer with 10 nodes and ReLu activation function\n\nAdam optimiser and mean square error as loss function","metadata":{}},{"cell_type":"code","source":"# define the keras model for one hidden layer\nmodel = Sequential()\nmodel.add(Dense(10, input_shape=(8,), activation='relu'))\nmodel.add(Dense(1))\nmodel.compile(loss='mean_squared_error', optimizer='adam')","metadata":{"execution":{"iopub.status.busy":"2024-07-30T11:52:52.799836Z","iopub.execute_input":"2024-07-30T11:52:52.800723Z","iopub.status.idle":"2024-07-30T11:52:53.588007Z","shell.execute_reply.started":"2024-07-30T11:52:52.800686Z","shell.execute_reply":"2024-07-30T11:52:53.587047Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n","output_type":"stream"}]},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(predictors, target,test_size=0.3, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2024-07-30T11:52:56.046495Z","iopub.execute_input":"2024-07-30T11:52:56.047284Z","iopub.status.idle":"2024-07-30T11:52:56.053950Z","shell.execute_reply.started":"2024-07-30T11:52:56.047249Z","shell.execute_reply":"2024-07-30T11:52:56.053079Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"# Train the model on the training dataset we created before\n\nmodel.fit(\n    X_train, y_train, \n    validation_data=(X_test, y_test),\n    epochs=50,\n    batch_size=10\n)","metadata":{"execution":{"iopub.status.busy":"2024-07-30T08:57:54.204383Z","iopub.execute_input":"2024-07-30T08:57:54.204879Z","iopub.status.idle":"2024-07-30T08:58:04.763000Z","shell.execute_reply.started":"2024-07-30T08:57:54.204848Z","shell.execute_reply":"2024-07-30T08:58:04.761936Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Epoch 1/50\n\u001b[1m42/73\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 11677.9980 ","output_type":"stream"},{"name":"stderr","text":"WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nI0000 00:00:1722329875.910785     208 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 8812.1436 - val_loss: 927.4703\nEpoch 2/50\n\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 913.0039 - val_loss: 624.3834\nEpoch 3/50\n\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 666.7895 - val_loss: 428.2399\nEpoch 4/50\n\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 457.8812 - val_loss: 316.7010\nEpoch 5/50\n\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 348.3760 - val_loss: 243.9630\nEpoch 6/50\n\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 255.7957 - val_loss: 200.0468\nEpoch 7/50\n\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 212.5138 - val_loss: 167.6977\nEpoch 8/50\n\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 197.7705 - val_loss: 150.4951\nEpoch 9/50\n\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 152.7487 - val_loss: 145.0193\nEpoch 10/50\n\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 139.5972 - val_loss: 134.2231\nEpoch 11/50\n\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 136.2219 - val_loss: 132.9039\nEpoch 12/50\n\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 151.0256 - val_loss: 126.3919\nEpoch 13/50\n\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 127.4430 - val_loss: 123.6488\nEpoch 14/50\n\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 122.2191 - val_loss: 122.1449\nEpoch 15/50\n\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 112.8859 - val_loss: 118.7172\nEpoch 16/50\n\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 134.4180 - val_loss: 116.8667\nEpoch 17/50\n\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 130.6254 - val_loss: 118.9882\nEpoch 18/50\n\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 114.7235 - val_loss: 115.7014\nEpoch 19/50\n\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 121.0327 - val_loss: 113.4828\nEpoch 20/50\n\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 109.7370 - val_loss: 115.8816\nEpoch 21/50\n\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 112.0685 - val_loss: 113.3034\nEpoch 22/50\n\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 114.2700 - val_loss: 109.8299\nEpoch 23/50\n\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 134.0486 - val_loss: 109.8522\nEpoch 24/50\n\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 107.5692 - val_loss: 110.1494\nEpoch 25/50\n\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 116.5532 - val_loss: 109.6094\nEpoch 26/50\n\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 117.3204 - val_loss: 110.2540\nEpoch 27/50\n\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 109.4215 - val_loss: 108.9047\nEpoch 28/50\n\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 106.2188 - val_loss: 108.0273\nEpoch 29/50\n\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 114.9246 - val_loss: 107.9248\nEpoch 30/50\n\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 108.5426 - val_loss: 108.7076\nEpoch 31/50\n\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 108.1021 - val_loss: 116.1214\nEpoch 32/50\n\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 108.5503 - val_loss: 106.3042\nEpoch 33/50\n\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 115.6623 - val_loss: 134.3233\nEpoch 34/50\n\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 110.3255 - val_loss: 112.5657\nEpoch 35/50\n\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 112.0079 - val_loss: 105.9519\nEpoch 36/50\n\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 107.5809 - val_loss: 105.5143\nEpoch 37/50\n\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 115.4465 - val_loss: 106.1331\nEpoch 38/50\n\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 104.4454 - val_loss: 106.6973\nEpoch 39/50\n\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 103.9032 - val_loss: 114.1910\nEpoch 40/50\n\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 118.4562 - val_loss: 111.8587\nEpoch 41/50\n\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 104.9248 - val_loss: 105.5696\nEpoch 42/50\n\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 102.1690 - val_loss: 105.2114\nEpoch 43/50\n\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 103.1747 - val_loss: 108.9803\nEpoch 44/50\n\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 114.4348 - val_loss: 108.2804\nEpoch 45/50\n\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 117.4768 - val_loss: 106.2530\nEpoch 46/50\n\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 103.1027 - val_loss: 104.9383\nEpoch 47/50\n\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 99.5907 - val_loss: 103.9173\nEpoch 48/50\n\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 117.1534 - val_loss: 103.1669\nEpoch 49/50\n\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 102.9001 - val_loss: 124.8850\nEpoch 50/50\n\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 111.1196 - val_loss: 105.5938\n","output_type":"stream"},{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"<keras.src.callbacks.history.History at 0x7ec258142b30>"},"metadata":{}}]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"## Evaluate the model on test data","metadata":{}},{"cell_type":"code","source":"y_pred = model.predict(X_test)\n#get the root mean squared error \nRMSE = round(sqrt(MSE(y_test, y_pred)),3)\nprint(\"Root mean square between predicted and test data\", RMSE)","metadata":{"execution":{"iopub.status.busy":"2024-07-30T08:58:07.734315Z","iopub.execute_input":"2024-07-30T08:58:07.734670Z","iopub.status.idle":"2024-07-30T08:58:08.139639Z","shell.execute_reply.started":"2024-07-30T08:58:07.734642Z","shell.execute_reply":"2024-07-30T08:58:08.138789Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\nRoot mean square between predicted and test data 10.276\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Repeat the training and evaluation process 50x","metadata":{}},{"cell_type":"code","source":"iterations=50\nRMSE=[] # An array to store the mean squared root values\nstart = time.time()\nfor i in range(1,iterations+1):\n    X_train, X_test, y_train, y_test = train_test_split(predictors, target,test_size=0.3, random_state=42)\n    # We use the verbose=0 option this time to go silent and not get hundreds of line of output\n    model.fit(\n    X_train, y_train, \n    validation_data=(X_test, y_test),\n    epochs=50,\n    batch_size=10,\n    verbose=0\n    )\n    y_pred = model.predict(X_test, verbose=0)\n    RMSE.append(round(sqrt(MSE(y_test, y_pred)),3))\n    # We don't want too many lines so we only print every 5 iterations\n    if i == 1 or i%5 == 0:\n        print(\"Iteration #\", i)\n        print(\"Mean squared error: \", RMSE[i-1])\n        \nend = time.time()\ntimer = round((end-start)/60,3)\nprint(f'The model took {timer} minutes to train')","metadata":{"execution":{"iopub.status.busy":"2024-07-30T10:32:51.298062Z","iopub.execute_input":"2024-07-30T10:32:51.298709Z","iopub.status.idle":"2024-07-30T10:39:25.441477Z","shell.execute_reply.started":"2024-07-30T10:32:51.298674Z","shell.execute_reply":"2024-07-30T10:39:25.440508Z"},"trusted":true},"execution_count":29,"outputs":[{"name":"stdout","text":"Iteration # 1\nMean squared error:  6.34\nIteration # 5\nMean squared error:  6.232\nIteration # 10\nMean squared error:  6.158\nIteration # 15\nMean squared error:  6.182\nIteration # 20\nMean squared error:  6.171\nIteration # 25\nMean squared error:  6.183\nIteration # 30\nMean squared error:  6.531\nIteration # 35\nMean squared error:  6.737\nIteration # 40\nMean squared error:  6.26\nIteration # 45\nMean squared error:  6.29\nIteration # 50\nMean squared error:  6.194\nThe model took 6.569 minutes to train\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Compute the mean and std of the mean squared error","metadata":{}},{"cell_type":"code","source":"RMSE_mean=round(np.mean(RMSE),3)\nRMSE_std=round(np.std(RMSE),3)\n\nprint(f\" After {iterations} iterations, the mean squared error mean is {RMSE_mean} and the std is {RMSE_std} \")","metadata":{"execution":{"iopub.status.busy":"2024-07-30T10:31:39.245832Z","iopub.execute_input":"2024-07-30T10:31:39.246530Z","iopub.status.idle":"2024-07-30T10:31:39.252643Z","shell.execute_reply.started":"2024-07-30T10:31:39.246495Z","shell.execute_reply":"2024-07-30T10:31:39.251411Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stdout","text":" After 50 iterations, the mean squared error mean is 6.353 and the std is 0.188 \n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Part B: analysis using normalised data","metadata":{}},{"cell_type":"markdown","source":"We first need to normalise the dataset using a simple formula : norm = (value - mean)/std","metadata":{}},{"cell_type":"code","source":"predictors_norm = (predictors - predictors.mean()) / predictors.std()\npredictors_norm.head()","metadata":{"execution":{"iopub.status.busy":"2024-07-30T11:51:42.901868Z","iopub.execute_input":"2024-07-30T11:51:42.902730Z","iopub.status.idle":"2024-07-30T11:51:42.920563Z","shell.execute_reply.started":"2024-07-30T11:51:42.902698Z","shell.execute_reply":"2024-07-30T11:51:42.919671Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"     Cement  Blast Furnace Slag   Fly Ash     Water  Superplasticizer  \\\n0  2.476712           -0.856472 -0.846733 -0.916319         -0.620147   \n1  2.476712           -0.856472 -0.846733 -0.916319         -0.620147   \n2  0.491187            0.795140 -0.846733  2.174405         -1.038638   \n3  0.491187            0.795140 -0.846733  2.174405         -1.038638   \n4 -0.790075            0.678079 -0.846733  0.488555         -1.038638   \n\n   Coarse Aggregate  Fine Aggregate       Age  \n0          0.862735       -1.217079 -0.279597  \n1          1.055651       -1.217079 -0.279597  \n2         -0.526262       -2.239829  3.551340  \n3         -0.526262       -2.239829  5.055221  \n4          0.070492        0.647569  4.976069  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Cement</th>\n      <th>Blast Furnace Slag</th>\n      <th>Fly Ash</th>\n      <th>Water</th>\n      <th>Superplasticizer</th>\n      <th>Coarse Aggregate</th>\n      <th>Fine Aggregate</th>\n      <th>Age</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2.476712</td>\n      <td>-0.856472</td>\n      <td>-0.846733</td>\n      <td>-0.916319</td>\n      <td>-0.620147</td>\n      <td>0.862735</td>\n      <td>-1.217079</td>\n      <td>-0.279597</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2.476712</td>\n      <td>-0.856472</td>\n      <td>-0.846733</td>\n      <td>-0.916319</td>\n      <td>-0.620147</td>\n      <td>1.055651</td>\n      <td>-1.217079</td>\n      <td>-0.279597</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.491187</td>\n      <td>0.795140</td>\n      <td>-0.846733</td>\n      <td>2.174405</td>\n      <td>-1.038638</td>\n      <td>-0.526262</td>\n      <td>-2.239829</td>\n      <td>3.551340</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.491187</td>\n      <td>0.795140</td>\n      <td>-0.846733</td>\n      <td>2.174405</td>\n      <td>-1.038638</td>\n      <td>-0.526262</td>\n      <td>-2.239829</td>\n      <td>5.055221</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>-0.790075</td>\n      <td>0.678079</td>\n      <td>-0.846733</td>\n      <td>0.488555</td>\n      <td>-1.038638</td>\n      <td>0.070492</td>\n      <td>0.647569</td>\n      <td>4.976069</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"iterations=50\nRMSE=[] # An array to store the mean squared root values\nstart = time.time()\nfor i in range(1,iterations+1):\n    X_train, X_test, y_train, y_test = train_test_split(predictors, target,test_size=0.3, random_state=42)\n    # We use the verbose=0 option this time to go silent and not get hundreds of line of output\n    model.fit(\n    X_train, y_train, \n    validation_data=(X_test, y_test),\n    epochs=50,\n    batch_size=10,\n    verbose=0\n    )\n    y_pred = model.predict(X_test, verbose=0)\n    RMSE.append(round(sqrt(MSE(y_test, y_pred)),3))\n    # We don't want too many lines so we only print every 5 iterations\n    if i == 1 or i%5 == 0:\n        print(\"Iteration #\", i)\n        print(\"Mean squared error: \", RMSE[i-1])\n        \nend = time.time()\ntimer = round((end-start)/60,3)\nprint(f'The model took {timer} minutes to train')","metadata":{"execution":{"iopub.status.busy":"2024-07-30T11:53:01.314108Z","iopub.execute_input":"2024-07-30T11:53:01.314456Z","iopub.status.idle":"2024-07-30T11:59:43.358847Z","shell.execute_reply.started":"2024-07-30T11:53:01.314428Z","shell.execute_reply":"2024-07-30T11:59:43.357855Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stderr","text":"WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nI0000 00:00:1722340383.108798     126 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n","output_type":"stream"},{"name":"stdout","text":"Iteration # 1\nMean squared error:  13.495\nIteration # 5\nMean squared error:  9.391\nIteration # 10\nMean squared error:  7.004\nIteration # 15\nMean squared error:  7.061\nIteration # 20\nMean squared error:  7.196\nIteration # 25\nMean squared error:  6.981\nIteration # 30\nMean squared error:  7.02\nIteration # 35\nMean squared error:  6.988\nIteration # 40\nMean squared error:  7.009\nIteration # 45\nMean squared error:  7.826\nIteration # 50\nMean squared error:  7.134\nThe model took 6.701 minutes to train\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Here's the results of the training on normalised data:","metadata":{}},{"cell_type":"code","source":"RMSE_mean_PartB=round(np.mean(RMSE),3)\nRMSE_std_PartB=round(np.std(RMSE),3)\n\nprint(f\" After {iterations} iterations, the mean squared error mean is {RMSE_mean_PartB} and the std is {RMSE_std_PartB} \")","metadata":{"execution":{"iopub.status.busy":"2024-07-30T12:03:39.816749Z","iopub.execute_input":"2024-07-30T12:03:39.817431Z","iopub.status.idle":"2024-07-30T12:03:39.823189Z","shell.execute_reply.started":"2024-07-30T12:03:39.817402Z","shell.execute_reply":"2024-07-30T12:03:39.822142Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":" After 50 iterations, the mean squared error mean is 7.539 and the std is 1.17 \n","output_type":"stream"}]},{"cell_type":"markdown","source":"Now we want to compare the values of the mean squared error mean and std on raw (Part A) and normalised data\n\nUnnormalised data (Part A):\nmean = 6.353\nstd = 0.188\n\nNormalised data:\nmean = 7.539 \nstd = 1.17\n\nThe mean is a bit higher and the std much higher.","metadata":{}},{"cell_type":"markdown","source":"# Part C: use normalised data ewith 100 epochs for the training","metadata":{}},{"cell_type":"code","source":"iterations=50\nRMSE=[] # An array to store the mean squared root values\nstart = time.time()\nfor i in range(1,iterations+1):\n    X_train, X_test, y_train, y_test = train_test_split(predictors, target,test_size=0.3, random_state=42)\n    # We use the verbose=0 option this time to go silent and not get hundreds of line of output\n    model.fit(\n    X_train, y_train, \n    validation_data=(X_test, y_test),\n    epochs=100,\n    batch_size=10,\n    verbose=0\n    )\n    y_pred = model.predict(X_test, verbose=0)\n    RMSE.append(round(sqrt(MSE(y_test, y_pred)),3))\n    # We don't want too many lines so we only print every 5 iterations\n    if i == 1 or i%5 == 0:\n        print(\"Iteration #\", i)\n        print(\"Mean squared error: \", RMSE[i-1])\n        \nend = time.time()\ntimer = round((end-start)/60,3)\nprint(f'The model took {timer} minutes to train')","metadata":{"execution":{"iopub.status.busy":"2024-07-30T12:09:17.064474Z","iopub.execute_input":"2024-07-30T12:09:17.065138Z","iopub.status.idle":"2024-07-30T12:22:32.987717Z","shell.execute_reply.started":"2024-07-30T12:09:17.065107Z","shell.execute_reply":"2024-07-30T12:22:32.986689Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"Iteration # 1\nMean squared error:  7.495\nIteration # 5\nMean squared error:  7.083\nIteration # 10\nMean squared error:  7.255\nIteration # 15\nMean squared error:  7.092\nIteration # 20\nMean squared error:  7.134\nIteration # 25\nMean squared error:  7.108\nIteration # 30\nMean squared error:  7.295\nIteration # 35\nMean squared error:  7.063\nIteration # 40\nMean squared error:  7.097\nIteration # 45\nMean squared error:  7.067\nIteration # 50\nMean squared error:  7.269\nThe model took 13.265 minutes to train\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Here are the results:","metadata":{}},{"cell_type":"code","source":"RMSE_mean_PartC=round(np.mean(RMSE),3)\nRMSE_std_PartC=round(np.std(RMSE),3)\n\nprint(f\" After {iterations} iterations, the mean squared error mean is {RMSE_mean_PartC} and the std is {RMSE_std_PartC} \")","metadata":{"execution":{"iopub.status.busy":"2024-07-30T12:28:46.992213Z","iopub.execute_input":"2024-07-30T12:28:46.992863Z","iopub.status.idle":"2024-07-30T12:28:46.998573Z","shell.execute_reply.started":"2024-07-30T12:28:46.992831Z","shell.execute_reply":"2024-07-30T12:28:46.997598Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":" After 50 iterations, the mean squared error mean is 7.229 and the std is 0.234 \n","output_type":"stream"}]},{"cell_type":"markdown","source":"Now the std is smaller, so using more epochs although it slows down the training 2x, improves significantly the std.","metadata":{}},{"cell_type":"markdown","source":"# Part D: add more layers to the neural network","metadata":{}},{"cell_type":"code","source":"# define the keras model for one hidden layer\nmodel = Sequential()\nmodel.add(Dense(10, input_shape=(8,), activation='relu'))\nmodel.add(Dense(10, activation='relu'))\nmodel.add(Dense(10, activation='relu'))\nmodel.add(Dense(1))\nmodel.compile(loss='mean_squared_error', optimizer='adam')","metadata":{"execution":{"iopub.status.busy":"2024-07-30T12:31:18.908667Z","iopub.execute_input":"2024-07-30T12:31:18.909037Z","iopub.status.idle":"2024-07-30T12:31:18.960085Z","shell.execute_reply.started":"2024-07-30T12:31:18.909009Z","shell.execute_reply":"2024-07-30T12:31:18.959201Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n","output_type":"stream"}]},{"cell_type":"code","source":"iterations=50\nRMSE=[] # An array to store the mean squared root values\nstart = time.time()\nfor i in range(1,iterations+1):\n    X_train, X_test, y_train, y_test = train_test_split(predictors, target,test_size=0.3, random_state=42)\n    # We use the verbose=0 option this time to go silent and not get hundreds of line of output\n    model.fit(\n    X_train, y_train, \n    validation_data=(X_test, y_test),\n    epochs=50,\n    batch_size=10,\n    verbose=0\n    )\n    y_pred = model.predict(X_test, verbose=0)\n    RMSE.append(round(sqrt(MSE(y_test, y_pred)),3))\n    # We don't want too many lines so we only print every 5 iterations\n    if i == 1 or i%5 == 0:\n        print(\"Iteration #\", i)\n        print(\"Mean squared error: \", RMSE[i-1])\n        \nend = time.time()\ntimer = round((end-start)/60,3)\nprint(f'The model took {timer} minutes to train')","metadata":{"execution":{"iopub.status.busy":"2024-07-30T12:31:42.026699Z","iopub.execute_input":"2024-07-30T12:31:42.027081Z","iopub.status.idle":"2024-07-30T12:38:57.130325Z","shell.execute_reply.started":"2024-07-30T12:31:42.027052Z","shell.execute_reply":"2024-07-30T12:38:57.129393Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"Iteration # 1\nMean squared error:  7.3\nIteration # 5\nMean squared error:  6.898\nIteration # 10\nMean squared error:  6.364\nIteration # 15\nMean squared error:  6.362\nIteration # 20\nMean squared error:  6.25\nIteration # 25\nMean squared error:  6.213\nIteration # 30\nMean squared error:  6.362\nIteration # 35\nMean squared error:  6.639\nIteration # 40\nMean squared error:  6.479\nIteration # 45\nMean squared error:  6.289\nIteration # 50\nMean squared error:  6.324\nThe model took 7.252 minutes to train\n","output_type":"stream"}]},{"cell_type":"code","source":"RMSE_mean_PartD=round(np.mean(RMSE),3)\nRMSE_std_PartD=round(np.std(RMSE),3)\n\nprint(f\" After {iterations} iterations, the mean squared error mean is {RMSE_mean_PartD} and the std is {RMSE_std_PartD} \")","metadata":{"execution":{"iopub.status.busy":"2024-07-30T13:14:15.132916Z","iopub.execute_input":"2024-07-30T13:14:15.133280Z","iopub.status.idle":"2024-07-30T13:14:15.140741Z","shell.execute_reply.started":"2024-07-30T13:14:15.133253Z","shell.execute_reply":"2024-07-30T13:14:15.139709Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":" After 50 iterations, the mean squared error mean is 6.489 and the std is 0.288 \n","output_type":"stream"}]}]}